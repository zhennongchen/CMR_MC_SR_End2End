{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/Documents')\n",
    "import CMR_HFpEF_Analysis.Defaults as Defaults\n",
    "import CMR_HFpEF_Analysis.functions_collection as ff\n",
    "import CMR_HFpEF_Analysis.Image_utils as util\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "main_path = '/mnt/mount_zc_NAS/HFpEF/data/HFpEF_data/Patient_list'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract the radiology report for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 21)\n"
     ]
    }
   ],
   "source": [
    "patient_list = pd.read_excel(os.path.join(main_path, 'AccessionNumber_ID_list.xlsx'))\n",
    "print(patient_list.shape)\n",
    "\n",
    "with open(os.path.join(main_path, 'QL033_20180802_221352_Rad.txt'), 'r') as file:\n",
    "    # Read the entire contents of the file\n",
    "    rad_reports = file.read()\n",
    "\n",
    "with open(os.path.join(main_path, 'QL033_20180802_221352_Car.txt'), 'r') as file:\n",
    "    # Read the entire contents of the file\n",
    "    car_reports = file.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### main script\n",
    "LVEF_list = []\n",
    "for no in range(0,patient_list.shape[0]):\n",
    "    print(no)\n",
    "    accession = str(patient_list['AccessionNumber'].iloc[no])\n",
    "    mrn = str(patient_list['PatientID(MRN)'].iloc[no])\n",
    "    ourID = patient_list['OurID'].iloc[no]\n",
    "\n",
    "    report_content = find_individual_report(rad_reports, accession, mrn, ourID)\n",
    "    if len(report_content) == 1:\n",
    "        report_content = find_individual_report(car_reports, accession, mrn, ourID)\n",
    "\n",
    "        if len(report_content) == 1: # neither in cardiology nor in radiology:\n",
    "            print('this one we couldn not find the report')\n",
    "            LVEF_list.append([ourID, mrn, accession, 'no', 0])\n",
    "            continue\n",
    "\n",
    "    \n",
    "    LVEF = find_LVEF(report_content)\n",
    "\n",
    "\n",
    "    LVEF_list.append([ourID, mrn, accession, 'yes', LVEF])\n",
    "\n",
    "    df = pd.DataFrame(LVEF_list, columns=['OurID', 'PatientID(MRN)', 'AccessionNumber', 'Find report?', 'LVEF'])\n",
    "    df.to_excel(os.path.join(main_path, 'LVEF_list.xlsx'),index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_individual_report(report, accession, mrn, ourID):\n",
    "\n",
    "    lines = rad_reports.splitlines()\n",
    "\n",
    "    # Initialize a list to store the line numbers where the sequence is found\n",
    "    matching_lines_numbers = []\n",
    "    # matching_lines_contents =[]\n",
    "\n",
    "    # Iterate over each line and check if the sequence is present\n",
    "    for i, line in enumerate(lines):\n",
    "        if accession in line and mrn in line:\n",
    "            matching_lines_numbers.append(i)  # Adding 1 to adjust for 0-based indexing\n",
    "            # matching_lines_contents.append(line)\n",
    "    \n",
    "    if len(matching_lines_numbers) == 0:\n",
    "        return ['']\n",
    "\n",
    "    # write the report for this patient\n",
    "    report_content = []; count = 0\n",
    "    while True:\n",
    "        l = lines[matching_lines_numbers[0] +count ]\n",
    "        report_content.append(l)\n",
    "        if 'report_end' in l:\n",
    "            break\n",
    "        if count > 500:\n",
    "            break\n",
    "        count += 1\n",
    "    \n",
    "    if ourID < 10:\n",
    "        ourID = '000' + str(ourID)\n",
    "    elif ourID >= 10 and ourID < 100:\n",
    "        ourID = '00' + str(ourID)\n",
    "    elif ourID >= 100 and ourID<1000:\n",
    "        ourID = '0' + str(ourID)\n",
    "    else:\n",
    "        ourID = str(ourID)\n",
    "\n",
    "    filename = 'ID_' + ourID + '_AccessionNumber_' + accession + '.txt'\n",
    "    with open(os.path.join(main_path,'individual_reports', filename), 'w') as file:\n",
    "        # Iterate over the list and write each element to a new line\n",
    "        for item in report_content:\n",
    "            file.write(item + '\\n')\n",
    "    \n",
    "    return report_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_LVEF(report_content):\n",
    "    # find line that has LVEF info\n",
    "    LVEF_line_numbers = []; full = []\n",
    "    for ii, line in enumerate(report_content):\n",
    "        if 'LVEF' in line:\n",
    "            LVEF_line_numbers.append(ii); full.append(0)\n",
    "        if 'left ventricular ejection fraction' in line:\n",
    "            LVEF_line_numbers.append(ii); full.append(1)\n",
    "\n",
    "    if len(LVEF_line_numbers) == 0:\n",
    "        # no LVEF info\n",
    "        return 0\n",
    "   \n",
    "    for ii in range(0,len(LVEF_line_numbers)):\n",
    "        LVEF_line = report_content[LVEF_line_numbers[ii]]\n",
    "\n",
    "        after = 0; ahead = 0; next_line = 0; LVEF = 0\n",
    "\n",
    "        if full[ii] == 0:\n",
    "            indexes = LVEF_line.find('LVEF')\n",
    "            indexes = indexes + 3\n",
    "        else: \n",
    "            indexes = LVEF_line.find('left ventricular ejection fraction')\n",
    "            indexes = indexes + 33\n",
    "\n",
    "        # after the key word\n",
    "        for n in range(indexes, len(LVEF_line)):\n",
    "            if '0' == LVEF_line[n] or '1' == LVEF_line[n] or '2' == LVEF_line[n] or '3' == LVEF_line[n] or '4' == LVEF_line[n] or '5' == LVEF_line[n] or '6' == LVEF_line[n] or '7' == LVEF_line[n] or '8' == LVEF_line[n] or '9' == LVEF_line[n]:\n",
    "                LVEF_letters = []\n",
    "                nn = 0\n",
    "                while True:\n",
    "                    if n + nn == len(LVEF_line):\n",
    "                        break\n",
    "                    if LVEF_line[n + nn] == ' ' or LVEF_line[n + nn] == '%' or LVEF_line[n + nn] == '-' or LVEF_line[n + nn] == '~':\n",
    "                        break\n",
    "                    LVEF_letters.append(LVEF_line[n+nn])\n",
    "                    nn += 1\n",
    "                LVEF = float(LVEF_line[n : n + len(LVEF_letters)]); after = 1\n",
    "                break\n",
    "\n",
    "        # ahead of the key word\n",
    "        if after == 0:\n",
    "            for n in np.arange(indexes, indexes-8, -1):\n",
    "                if '0' == LVEF_line[n] or '1' == LVEF_line[n] or '2' == LVEF_line[n] or '3' == LVEF_line[n] or '4' == LVEF_line[n] or '5' == LVEF_line[n] or '6' == LVEF_line[n] or '7' == LVEF_line[n] or '8' == LVEF_line[n] or '9' == LVEF_line[n]:\n",
    "                    LVEF_letters = []\n",
    "                    nn = 0\n",
    "                    while True:\n",
    "                        if n - nn < 0:\n",
    "                            break\n",
    "                        if LVEF_line[n - nn] == ' ' or LVEF_line[n - nn] == '%' or LVEF_line[n - nn] == '-' or LVEF_line[n - nn] == '~':\n",
    "                            break\n",
    "                        LVEF_letters.append(LVEF_line[n - nn])\n",
    "                        nn += 1\n",
    "                    LVEF = float(LVEF_line[n - len(LVEF_letters) : n ]); ahead = 1\n",
    "                    break\n",
    "\n",
    "        # next line\n",
    "        if after == 0 and ahead == 0:\n",
    "            LVEF_line_next = report_content[LVEF_line_numbers[ii] + 1]\n",
    "            for n in range(0,5):\n",
    "                if n>=len(LVEF_line_next):\n",
    "                    break\n",
    "                if '0' == LVEF_line_next[n] or '1' == LVEF_line_next[n] or '2' == LVEF_line_next[n] or '3' == LVEF_line_next[n] or '4' == LVEF_line_next[n] or '5' == LVEF_line_next[n] or '6' == LVEF_line_next[n] or '7' == LVEF_line_next[n] or '8' == LVEF_line_next[n] or '9' == LVEF_line_next[n]:\n",
    "                    LVEF_letters = []\n",
    "                    nn = 0\n",
    "                    while True:\n",
    "                        if n + nn == 10:\n",
    "                            break\n",
    "                        if LVEF_line_next[n + nn] == ' ' or LVEF_line_next[n + nn] == '%' or LVEF_line_next[n + nn] == '-' or LVEF_line_next[n + nn] == '~':\n",
    "                            break\n",
    "                        LVEF_letters.append(LVEF_line_next[n + nn])\n",
    "                        nn += 1\n",
    "                    LVEF = float(LVEF_line_next[n: n+ len(LVEF_letters) ]); next_line = 1\n",
    "                    break\n",
    "\n",
    "        if LVEF != 0:\n",
    "            return LVEF\n",
    "        \n",
    "    if LVEF == 0: # no numerical value of LVEF:\n",
    "        return 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop duplicated cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 21)\n",
      "(1418, 21)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(os.path.join(main_path, 'HF_Patient_list_w_duplicated_images.xlsx'))\n",
    "print(df.shape)\n",
    "df = df.drop_duplicates(subset='AccessionNumber')\n",
    "print(df.shape)\n",
    "\n",
    "df.to_excel(os.path.join(main_path, 'HF_Patient_list.xlsx'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find out the unique patient and all his/her scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(os.path.join(main_path, 'HF_Patient_list_no_duplicated_images.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each unique MRN is a unique patient\n",
    "unique_mrn = []\n",
    "unique_row_index = []\n",
    "\n",
    "Result = []\n",
    "for i in range(0, data.shape[0]):\n",
    "    case = data.iloc[i]\n",
    "    mrn = case['PatientID(MRN)']\n",
    "\n",
    "    if mrn in unique_mrn:\n",
    "        continue\n",
    "    else:\n",
    "        unique_mrn.append(mrn)\n",
    "\n",
    "    # rows with the same mrn:\n",
    "    rows = data[data['PatientID(MRN)'] == mrn]\n",
    " \n",
    "    if rows.shape == 1:\n",
    "        unique_row_index.append(i)\n",
    "        dates_record = np.nan\n",
    "    else:\n",
    "        # this patient has more than 1 scans. let's pick the first one\n",
    "        sorted_rows = rows.sort_values(by='StudyDate')\n",
    "       \n",
    "        earliest_scan_index = data.loc[data['OurID'] == sorted_rows.iloc[0]['OurID']].index[0]\n",
    "        unique_row_index.append(earliest_scan_index)\n",
    "        \n",
    "        # then let's record the days between scans\n",
    "        dates = sorted_rows['StudyDate']\n",
    "        dates_record = []\n",
    "        for d in range(1,dates.shape[0] ):\n",
    "            date1 = datetime.strptime(str(dates.iloc[d-1]), '%Y%m%d')\n",
    "            date2 = datetime.strptime(str(dates.iloc[d]), '%Y%m%d')\n",
    "            dates_record.append((date2 - date1).days)\n",
    "        \n",
    "    Result.append([sorted_rows.iloc[0]['OurID'], rows.shape[0], dates_record])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(Result, columns = ['OurID', 'how_many_scans', 'days_between_scans'])\n",
    "\n",
    "unique_list = data.iloc[unique_row_index]\n",
    "\n",
    "# merge:\n",
    "merged_df = unique_list.merge(df, on='OurID', how = 'left')\n",
    "merged_df.to_excel(os.path.join(main_path, 'HF_Patient_list_unique_patient.xlsx'),index = False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge patient list with re-admission info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_str(value):\n",
    "    if isinstance(value, int) or (isinstance(value, str) and value.isdigit()):\n",
    "        return str(value)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_list = pd.read_excel(os.path.join(main_path, 'Important_HFpEF_Patient_list_unique_patient_w_notes.xlsx'))\n",
    "patient_list['AccessionNumber'] = patient_list['AccessionNumber'].apply(convert_to_str)\n",
    "\n",
    "re_p_1yr = pd.read_excel(os.path.join(main_path, 're-admission-info/readmission_P_1yr.xlsx'))\n",
    "re_p_1yr  = re_p_1yr.loc[:, ['AccessionNumber', 'flagReAdmissionWithinHalfYear']].copy()\n",
    "re_p_1yr.rename(columns = {'flagReAdmissionWithinHalfYear': 'Readmission_Primary_1yr'}, inplace = True)\n",
    "re_p_1yr['AccessionNumber'] = re_p_1yr['AccessionNumber'].apply(convert_to_str)\n",
    "\n",
    "re_ps_1yr = pd.read_excel(os.path.join(main_path, 're-admission-info/readmission_P+S_1yr.xlsx'))\n",
    "re_ps_1yr  = re_ps_1yr.loc[:, ['AccessionNumber', 'flagReAdmissionWithinHalfYear']].copy()\n",
    "re_ps_1yr.rename(columns = {'flagReAdmissionWithinHalfYear': 'Readmission_Primary+Secondary_1yr'}, inplace = True)\n",
    "re_ps_1yr['AccessionNumber'] = re_ps_1yr['AccessionNumber'].apply(convert_to_str)\n",
    "\n",
    "re = pd.merge(re_p_1yr, re_ps_1yr, on='AccessionNumber', how = 'inner')\n",
    "\n",
    "final = pd.merge(patient_list, re, on='AccessionNumber', how = 'inner')\n",
    "\n",
    "# also add the Readmission date and department\n",
    "re_ps_1yr = pd.read_excel(os.path.join(main_path, 're-admission-info/readmission_P+S_1yr.xlsx'))\n",
    "info = re_ps_1yr.loc[:, ['AccessionNumber', 'ReAdmissionDTS', 'DepartmentDSC', 'ADTEventTypeDSC']].copy()\n",
    "info['AccessionNumber'] = info['AccessionNumber'].apply(convert_to_str)\n",
    "\n",
    "final = pd.merge(final, info, on='AccessionNumber', how = 'inner')\n",
    "\n",
    "final.to_excel(os.path.join(main_path, 'Important_HFpEF_Patient_list_unique_patient_w_readmission.xlsx'),index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge HFpEF patient list with raw_data_correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_list = pd.read_excel(os.path.join(main_path, 'Important_HFpEF_Patient_list_unique_patient_w_readmission_finalized.xlsx'))\n",
    "raw_correspondence = pd.read_excel(os.path.join(main_path, 'raw_data_correspondence.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "count = 0\n",
    "for i in range(0,patient_list.shape[0]):\n",
    "    ourID = patient_list['OurID'].iloc[i]\n",
    "\n",
    "    # find this in raw_correrspondence\n",
    "    raw = raw_correspondence.loc[raw_correspondence['OurID'] == ourID]\n",
    "    folder_path = raw['folder_path'].iloc[0]\n",
    "\n",
    "    if len(str(folder_path))<5:\n",
    "        count += 1\n",
    "        have_raw_data = 'no'\n",
    "    else:\n",
    "        have_raw_data = 'yes'\n",
    "\n",
    "    result.append([ourID, patient_list['AccessionNumber'].iloc[i], have_raw_data, folder_path])\n",
    "\n",
    "df = pd.DataFrame(result, columns = ['OurID', 'AccessionNumber','have_raw_data', 'folder_path'])\n",
    "df.to_excel(os.path.join(main_path, 'raw_data_correspondence_HFpEF.xlsx'),index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
